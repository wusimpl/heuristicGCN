{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch_geometric.nn\n",
    "from torch_geometric.datasets import RelLinkPredDataset\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from helper import *\n",
    "from data_loader import *\n",
    "from tqdm import tqdm\n",
    "from model.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class Runner(object):\n",
    "\tdef __init__(self, params):\n",
    "\t\tself.p = params\n",
    "\t\tself.logger = get_logger(self.p.name, self.p.log_dir, self.p.config_dir)\n",
    "\n",
    "\t\t# self.logger.info(vars(self.p))\n",
    "\t\t# pprint(vars(self.p))\n",
    "\n",
    "\t\tif self.p.gpu != '-1' and torch.cuda.is_available():\n",
    "\t\t\tself.device = torch.device('cuda')\n",
    "\t\t\ttorch.cuda.set_rng_state(torch.cuda.get_rng_state())\n",
    "\t\t\ttorch.backends.cudnn.deterministic = True\n",
    "\t\telse:\n",
    "\t\t\tself.device = torch.device('cpu')\n",
    "\n",
    "\t\tself.load_data()\n",
    "\t\tself.model = self.add_model(self.p.model, self.p.score_func)\n",
    "\t\tself.optimizer = self.add_optimizer(self.model.parameters())\n",
    "\n",
    "\tdef __get_data_loader(self, data, split, batch_size, shuffle=True):\n",
    "\t\treturn  DataLoader(\n",
    "\t\t\t\tRLPDDataset(data, num_hops=2, split=split, device=self.device),\n",
    "\t\t\t\tbatch_size      = batch_size,\n",
    "\t\t\t\tshuffle         = shuffle,\n",
    "\t\t\t\tnum_workers     = max(0, self.p.num_workers),\n",
    "\t\t\t)\n",
    "\n",
    "\tdef load_data(self):\n",
    "\t\tself.p.embed_dim\t= self.p.k_w * self.p.k_h if self.p.embed_dim is None else self.p.embed_dim\n",
    "\n",
    "\t\tcurrent_directory = os.getcwd()\n",
    "\t\tdata_path = osp.join(current_directory, 'data', 'RLPD')\n",
    "\t\t##@@\n",
    "\t\t# data_path = osp.join(osp.dirname(osp.realpath(__file__)), '', 'data', 'RLPD')\n",
    "\n",
    "\t\tfull_data = RelLinkPredDataset(data_path, 'FB15k-237')[0]\n",
    "\t\tself.p.num_ent\t\t= full_data.num_nodes\n",
    "\t\tself.p.num_rel\t\t= full_data.edge_type.max() + 1 # 增加一种自环关系\n",
    "\n",
    "\t\ttransform = RandomLinkSplit(num_val=0.2, num_test=0.3,\n",
    "\t\t\t\t\t\t\t\t\tis_undirected=True, split_labels=True)\n",
    "\t\tself.edge_index, self.edge_type =full_data.edge_index, full_data.edge_type\n",
    "\t\tnon_split_data = Data(edge_index=full_data.edge_index, edge_type=full_data.edge_type, num_nodes=full_data.num_nodes)\n",
    "\t\ttrain_data, val_data, test_data = transform(non_split_data)\n",
    "\n",
    "\t\ttrain_data.pos_edge_label_type = train_data.edge_type[:train_data.pos_edge_label_index.shape[1]]\n",
    "\t\ttrain_data.neg_edge_label_type = train_data.edge_type[train_data.pos_edge_label_index.shape[1]:]\n",
    "\t\tval_data.pos_edge_label_type = val_data.edge_type[:val_data.pos_edge_label_index.shape[1]]\n",
    "\t\tval_data.neg_edge_label_type = val_data.edge_type[val_data.pos_edge_label_index.shape[1]:]\n",
    "\t\ttest_data.pos_edge_label_type = test_data.edge_type[:test_data.pos_edge_label_index.shape[1]]\n",
    "\t\ttest_data.neg_edge_label_type = test_data.edge_type[test_data.pos_edge_label_index.shape[1]:]\n",
    "\n",
    "\t\ttrain_data = train_data.to(self.device)\n",
    "\t\tval_data = val_data.to(self.device)\n",
    "\t\ttest_data = test_data.to(self.device)\n",
    "\n",
    "\t\t# 耗时操作\n",
    "\t\tself.data_iter = {\n",
    "\t\t\t'train':self.__get_data_loader(train_data, 'train', self.p.batch_size),\n",
    "\t\t\t'valid':self.__get_data_loader(val_data,   'valid', self.p.batch_size),\n",
    "\t\t\t'test': self.__get_data_loader(test_data,  'test',  self.p.batch_size)\n",
    "\t\t}\n",
    "\n",
    "\tdef add_model(self, model, score_func):\n",
    "\t\tmodel_name = '{}_{}'.format(model, score_func)\n",
    "\n",
    "\t\tif   model_name.lower()\t== 'compgcn_transe': \tmodel = CompGCN_TransE(self.edge_index, self.edge_type, params=self.p)\n",
    "\t\telif model_name.lower()\t== 'compgcn_distmult': \tmodel = CompGCN_DistMult(self.edge_index, self.edge_type, params=self.p)\n",
    "\t\telif model_name.lower()\t== 'compgcn_conve': \tmodel = CompGCN_ConvE(self.edge_index, self.edge_type, params=self.p)\n",
    "\t\telse: raise NotImplementedError\n",
    "\n",
    "\t\tmodel.to(self.device)\n",
    "\t\treturn model\n",
    "\n",
    "\tdef add_optimizer(self, parameters):\n",
    "\t\treturn torch.optim.Adam(parameters, lr=self.p.lr, weight_decay=self.p.l2)\n",
    "\n",
    "\tdef read_batch(self, batch, split):\n",
    "\t\t\"\"\"\n",
    "\t\tFunction to read a batch of data and move the tensors in batch to CPU/GPU\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tbatch: \t\tthe batch to process\n",
    "\t\tsplit: (string) If split == 'train', 'valid' or 'test' split\n",
    "\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tHead, Relation, Tails, labels\n",
    "\t\t\"\"\"\n",
    "\t\tif split == 'train':\n",
    "\t\t\ttriple, label = [ _.to(self.device) for _ in batch]\n",
    "\t\t\treturn triple[:, 0], triple[:, 1], triple[:, 2], label\n",
    "\t\telse:\n",
    "\t\t\ttriple, label = [ _.to(self.device) for _ in batch]\n",
    "\t\t\treturn triple[:, 0], triple[:, 1], triple[:, 2], label\n",
    "\n",
    "\tdef save_model(self, save_path):\n",
    "\t\tstate = {\n",
    "\t\t\t'state_dict'\t: self.model.state_dict(),\n",
    "\t\t\t'best_val'\t: self.best_val,\n",
    "\t\t\t'best_epoch'\t: self.best_epoch,\n",
    "\t\t\t'optimizer'\t: self.optimizer.state_dict(),\n",
    "\t\t\t'args'\t\t: vars(self.p)\n",
    "\t\t}\n",
    "\t\ttorch.save(state, save_path)\n",
    "\n",
    "\tdef load_model(self, load_path):\n",
    "\t\tstate\t\t\t= torch.load(load_path)\n",
    "\t\tstate_dict\t\t= state['state_dict']\n",
    "\t\tself.best_val\t\t= state['best_val']\n",
    "\t\tself.best_val_mrr\t= self.best_val['mrr']\n",
    "\n",
    "\t\tself.model.load_state_dict(state_dict)\n",
    "\t\tself.optimizer.load_state_dict(state['optimizer'])\n",
    "\n",
    "\tdef evaluate(self, split, epoch):\n",
    "\t\t\"\"\"\n",
    "\t\tFunction to evaluate the model on validation or test set\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tsplit: (string) If split == 'valid' then evaluate on the validation set, else the test set\n",
    "\t\tepoch: (int) Current epoch count\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tresutls:\t\t\tThe evaluation results containing the following:\n",
    "\t\t\tresults['mr']:         \tAverage of ranks_left and ranks_right\n",
    "\t\t\tresults['mrr']:         Mean Reciprocal Rank\n",
    "\t\t\tresults['hits@k']:      Probability of getting the correct preodiction in top-k ranks based on predicted score\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tleft_results  = self.predict(split=split, mode='tail_batch')\n",
    "\t\tright_results = self.predict(split=split, mode='head_batch')\n",
    "\t\tresults       = get_combined_results(left_results, right_results)\n",
    "\t\t# self.logger.info('[Epoch {} {}]: MRR: Tail : {:.5}, Head : {:.5}, Avg : {:.5}'.format(epoch, split, results['left_mrr'], results['right_mrr'], results['mrr']))\n",
    "\t\treturn results\n",
    "\n",
    "\tdef predict(self, split='valid', mode='tail_batch'):\n",
    "\t\t\"\"\"\n",
    "\t\tFunction to run model evaluation for a given mode\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tsplit: (string) \tIf split == 'valid' then evaluate on the validation set, else the test set\n",
    "\t\tmode: (string):\t\tCan be 'head_batch' or 'tail_batch'\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tresutls:\t\t\tThe evaluation results containing the following:\n",
    "\t\t\tresults['mr']:         \tAverage of ranks_left and ranks_right\n",
    "\t\t\tresults['mrr']:         Mean Reciprocal Rank\n",
    "\t\t\tresults['hits@k']:      Probability of getting the correct preodiction in top-k ranks based on predicted score\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tself.model.eval()\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tresults = {}\n",
    "\t\t\ttrain_iter = iter(self.data_iter['{}_{}'.format(split, mode.split('_')[0])])\n",
    "\n",
    "\t\t\tfor step, batch in enumerate(train_iter):\n",
    "\t\t\t\tsub, rel, obj, label\t= self.read_batch(batch, split)\n",
    "\t\t\t\tpred\t\t\t= self.model.forward(sub, rel)\n",
    "\t\t\t\tb_range\t\t\t= torch.arange(pred.size()[0], device=self.device)\n",
    "\t\t\t\ttarget_pred\t\t= pred[b_range, obj]\n",
    "\t\t\t\tpred \t\t\t= torch.where(label.byte(), -torch.ones_like(pred) * 10000000, pred)\n",
    "\t\t\t\tpred[b_range, obj] \t= target_pred\n",
    "\t\t\t\tranks\t\t\t= 1 + torch.argsort(torch.argsort(pred, dim=1, descending=True), dim=1, descending=False)[b_range, obj]\n",
    "\n",
    "\t\t\t\tranks \t\t\t= ranks.float()\n",
    "\t\t\t\tresults['count']\t= torch.numel(ranks) \t\t+ results.get('count', 0.0)\n",
    "\t\t\t\tresults['mr']\t\t= torch.sum(ranks).item() \t+ results.get('mr',    0.0)\n",
    "\t\t\t\tresults['mrr']\t\t= torch.sum(1.0/ranks).item()   + results.get('mrr',   0.0)\n",
    "\t\t\t\tfor k in range(10):\n",
    "\t\t\t\t\tresults['hits@{}'.format(k+1)] = torch.numel(ranks[ranks <= (k+1)]) + results.get('hits@{}'.format(k+1), 0.0)\n",
    "\n",
    "\t\t\t\t# if step % 100 == 0:\n",
    "\t\t\t\t# \tself.logger.info('[{}, {} Step {}]\\t{}'.format(split.title(), mode.title(), step, self.p.name))\n",
    "\n",
    "\t\treturn results\n",
    "\n",
    "\tdef train(self, epoch):\n",
    "\t\t\"\"\"\n",
    "\t\tFunction to run one epoch of training\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tepoch: current epoch count\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tloss: The loss value after the completion of one epoch\n",
    "\t\t\"\"\"\n",
    "\t\tself.model.train()\n",
    "\t\tlosses = []\n",
    "\t\ttrain_dataloader = iter(self.data_iter['train'])\n",
    "\n",
    "\t\tfor step, batch in enumerate(train_dataloader):\n",
    "\t\t\tself.optimizer.zero_grad()\n",
    "\t\t\tsub, rel, obj, label = self.read_batch(batch, 'train')\n",
    "\n",
    "\t\t\tpred\t= self.model.forward(sub, rel)\n",
    "\t\t\tloss\t= self.model.loss(pred, label)\n",
    "\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tself.optimizer.step()\n",
    "\t\t\tlosses.append(loss.item())\n",
    "\n",
    "\t\tloss = np.mean(losses)\n",
    "\t\t# self.logger.info('[Epoch:{}]:  Training Loss:{:.4}\\n'.format(epoch, loss))\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef fit(self):\n",
    "\t\tself.best_val_mrr, self.best_val, self.best_epoch, val_mrr = 0., {}, 0, 0.\n",
    "\t\tsave_path = os.path.join('./checkpoints', self.p.name)\n",
    "\n",
    "\t\tif self.p.restore:\n",
    "\t\t\tself.load_model(save_path)\n",
    "\t\t\tself.logger.info('Successfully Loaded previous model')\n",
    "\n",
    "\t\tkill_cnt = 0\n",
    "\t\tfor epoch in range(self.p.max_epochs):\n",
    "\t\t\ttrain_loss  = self.train(epoch)\n",
    "\t\t\tval_results = self.evaluate('valid', epoch)\n",
    "\t\t\tif val_results['mrr'] > self.best_val_mrr:\n",
    "\t\t\t\tself.best_val\t   = val_results\n",
    "\t\t\t\tself.best_val_mrr  = val_results['mrr']\n",
    "\t\t\t\tself.best_epoch\t   = epoch\n",
    "\t\t\t\tself.save_model(save_path)\n",
    "\t\t\t\tkill_cnt = 0\n",
    "\t\t\telse:\n",
    "\t\t\t\tkill_cnt += 1\n",
    "\t\t\t\tif kill_cnt % 10 == 0 and self.p.gamma > 5:\n",
    "\t\t\t\t\tself.p.gamma -= 5\n",
    "\t\t\t\t\tself.logger.info('Gamma decay on saturation, updated value of gamma: {}'.format(self.p.gamma))\n",
    "\t\t\t\tif kill_cnt > 25:\n",
    "\t\t\t\t\tself.logger.info(\"Early Stopping!!\")\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\tself.logger.info('[Epoch {:2}]: Train loss: {:.4} Valid MRR: {:.3} Best MRR: {:.3} hits@1: {:.3} hits@3: {:.3} hits@10: {:.3}'\n",
    "\t\t\t\t\t\t\t .format(epoch,train_loss,val_results['mrr'],self.best_val_mrr,val_results['hits@1'],val_results['hits@3'],val_results['hits@10']))\n",
    "\n",
    "\t\tself.logger.info('Loading best model, Evaluating on Test data')\n",
    "\t\tself.load_model(save_path)\n",
    "\t\ttest_results = self.evaluate('test', epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def load_args():\n",
    "\tparser = argparse.ArgumentParser(description='Parser For Arguments',\n",
    "\t\t\t\t\t\t\t\t\t formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "\tparser.add_argument('-name', default='testrun', help='Set run name for saving/restoring models')\n",
    "\tparser.add_argument('-data', dest='dataset', default='FB15k-237', help='Dataset to use, default: FB15k-237')\n",
    "\tparser.add_argument('-model', dest='model', default='compgcn', help='Model Name')\n",
    "\tparser.add_argument('-score_func', dest='score_func', default='conve', help='Score Function for Link prediction')\n",
    "\tparser.add_argument('-opn', dest='opn', default='corr', help='Composition Operation to be used in CompGCN')\n",
    "\n",
    "\tparser.add_argument('-batch', dest='batch_size', default=128, type=int, help='Batch size')\n",
    "\tparser.add_argument('-gamma', type=float, default=40.0, help='Margin')\n",
    "\tparser.add_argument('-gpu', type=str, default='0', help='Set GPU Ids : Eg: For CPU = -1, For Single GPU = 0')\n",
    "\tparser.add_argument('-epoch', dest='max_epochs', type=int, default=500, help='Number of epochs')\n",
    "\tparser.add_argument('-l2', type=float, default=0.0, help='L2 Regularization for Optimizer')\n",
    "\tparser.add_argument('-lr', type=float, default=0.001, help='Starting Learning Rate')\n",
    "\tparser.add_argument('-lbl_smooth', dest='lbl_smooth', type=float, default=0.1, help='Label Smoothing')\n",
    "\tparser.add_argument('-num_workers', type=int, default=10, help='Number of processes to construct batches')\n",
    "\tparser.add_argument('-seed', dest='seed', default=41504, type=int, help='Seed for randomization')\n",
    "\n",
    "\tparser.add_argument('-restore', dest='restore', action='store_true', help='Restore from the previously saved model')\n",
    "\tparser.add_argument('-bias', dest='bias', action='store_true', help='Whether to use bias in the model')\n",
    "\n",
    "\tparser.add_argument('-num_bases', dest='num_bases', default=-1, type=int,\n",
    "\t\t\t\t\t\thelp='Number of basis relation vectors to use')\n",
    "\tparser.add_argument('-init_dim', dest='init_dim', default=100, type=int,\n",
    "\t\t\t\t\t\thelp='Initial dimension size for entities and relations')\n",
    "\tparser.add_argument('-gcn_dim', dest='gcn_dim', default=200, type=int, help='Number of hidden units in GCN')\n",
    "\tparser.add_argument('-embed_dim', dest='embed_dim', default=None, type=int,\n",
    "\t\t\t\t\t\thelp='Embedding dimension to give as input to score function')\n",
    "\tparser.add_argument('-gcn_layer', dest='gcn_layer', default=1, type=int, help='Number of GCN Layers to use')\n",
    "\tparser.add_argument('-gcn_drop', dest='dropout', default=0.1, type=float, help='Dropout to use in GCN Layer')\n",
    "\tparser.add_argument('-hid_drop', dest='hid_drop', default=0.3, type=float, help='Dropout after GCN')\n",
    "\n",
    "\t# ConvE specific hyperparameters\n",
    "\tparser.add_argument('-hid_drop2', dest='hid_drop2', default=0.3, type=float, help='ConvE: Hidden dropout')\n",
    "\tparser.add_argument('-feat_drop', dest='feat_drop', default=0.3, type=float, help='ConvE: Feature Dropout')\n",
    "\tparser.add_argument('-k_w', dest='k_w', default=10, type=int, help='ConvE: k_w')\n",
    "\tparser.add_argument('-k_h', dest='k_h', default=20, type=int, help='ConvE: k_h')\n",
    "\tparser.add_argument('-num_filt', dest='num_filt', default=200, type=int,\n",
    "\t\t\t\t\t\thelp='ConvE: Number of filters in convolution')\n",
    "\tparser.add_argument('-ker_sz', dest='ker_sz', default=7, type=int, help='ConvE: Kernel size to use')\n",
    "\n",
    "\tparser.add_argument('-logdir', dest='log_dir', default='./log/', help='Log directory')\n",
    "\tparser.add_argument('-config', dest='config_dir', default='./config/', help='Config directory')\n",
    "\n",
    "\targ_list = ['-score_func', 'distmult', '-opn', 'mult', '-gamma', '9', '-hid_drop', '0.2', '-init_dim', '200', '-lr', '1e-3', '-data', 'FB15k-237', '-batch', '100', '-epoch', '20']\n",
    "\targs = parser.parse_args(args=arg_list)\n",
    "\t##@@\n",
    "\t# args = parser.parse_args()\n",
    "\n",
    "\treturn args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-23 20:40:36,135 - [INFO] - {'name': 'testrun_23_08_2023_20:40:36', 'dataset': 'FB15k-237', 'model': 'compgcn', 'score_func': 'distmult', 'opn': 'mult', 'batch_size': 100, 'gamma': 9.0, 'gpu': '0', 'max_epochs': 20, 'l2': 0.0, 'lr': 0.001, 'lbl_smooth': 0.1, 'num_workers': 10, 'seed': 41504, 'restore': False, 'bias': False, 'num_bases': -1, 'init_dim': 200, 'gcn_dim': 200, 'embed_dim': None, 'gcn_layer': 1, 'dropout': 0.1, 'hid_drop': 0.2, 'hid_drop2': 0.3, 'feat_drop': 0.3, 'k_w': 10, 'k_h': 20, 'num_filt': 200, 'ker_sz': 7, 'log_dir': './log/', 'config_dir': './config/'}\n",
      "{'batch_size': 100,\n",
      " 'bias': False,\n",
      " 'config_dir': './config/',\n",
      " 'dataset': 'FB15k-237',\n",
      " 'dropout': 0.1,\n",
      " 'embed_dim': None,\n",
      " 'feat_drop': 0.3,\n",
      " 'gamma': 9.0,\n",
      " 'gcn_dim': 200,\n",
      " 'gcn_layer': 1,\n",
      " 'gpu': '0',\n",
      " 'hid_drop': 0.2,\n",
      " 'hid_drop2': 0.3,\n",
      " 'init_dim': 200,\n",
      " 'k_h': 20,\n",
      " 'k_w': 10,\n",
      " 'ker_sz': 7,\n",
      " 'l2': 0.0,\n",
      " 'lbl_smooth': 0.1,\n",
      " 'log_dir': './log/',\n",
      " 'lr': 0.001,\n",
      " 'max_epochs': 20,\n",
      " 'model': 'compgcn',\n",
      " 'name': 'testrun_23_08_2023_20:40:36',\n",
      " 'num_bases': -1,\n",
      " 'num_filt': 200,\n",
      " 'num_workers': 10,\n",
      " 'opn': 'mult',\n",
      " 'restore': False,\n",
      " 'score_func': 'distmult',\n",
      " 'seed': 41504}\n",
      "cached files found in /root/compGCN/data/RLPD/FB15k-237/cached/train.pt\n",
      "cached files found in /root/compGCN/data/RLPD/FB15k-237/cached/valid.pt\n",
      "cached files found in /root/compGCN/data/RLPD/FB15k-237/cached/test.pt\n"
     ]
    }
   ],
   "source": [
    "args = load_args()\n",
    "\n",
    "if not args.restore: args.name = args.name + '_' + time.strftime('%d_%m_%Y') + '_' + time.strftime('%H:%M:%S')\n",
    "\n",
    "set_gpu(args.gpu)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "model = Runner(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/root/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/root/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/root/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 183, in default_collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torch_geometric.data.data.Data'>\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36mRunner.fit\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    224\u001B[0m kill_cnt \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    225\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mp\u001B[38;5;241m.\u001B[39mmax_epochs):\n\u001B[0;32m--> 226\u001B[0m \ttrain_loss  \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m \tval_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluate(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalid\u001B[39m\u001B[38;5;124m'\u001B[39m, epoch)\n\u001B[1;32m    228\u001B[0m \t\u001B[38;5;28;01mif\u001B[39;00m val_results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmrr\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_val_mrr:\n",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36mRunner.train\u001B[0;34m(self, epoch)\u001B[0m\n\u001B[1;32m    198\u001B[0m losses \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    199\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_iter[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m--> 201\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_dataloader):\n\u001B[1;32m    202\u001B[0m \t\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m    203\u001B[0m \tsub, rel, obj, label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread_batch(batch, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    678\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    679\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    680\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 681\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    683\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    684\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    685\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1376\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1374\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1375\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[idx]\n\u001B[0;32m-> 1376\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1402\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1400\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[1;32m   1401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[0;32m-> 1402\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1403\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_utils.py:461\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    457\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    458\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[1;32m    459\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[1;32m    460\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m--> 461\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[0;31mTypeError\u001B[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/root/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/root/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/root/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 183, in default_collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torch_geometric.data.data.Data'>\n"
     ]
    }
   ],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
